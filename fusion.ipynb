{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7118a0e2-9084-4516-82a1-9ea1a308c794",
   "metadata": {},
   "source": [
    "# Preparación de los nuevos datos para su posterior fusión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b05516c3-4188-4e99-877f-5936cc1653ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b250243b-c660-45aa-92fd-5290ca65841a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyarrow in c:\\users\\carme\\anaconda3\\lib\\site-packages (16.1.0)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: numpy>=1.16.6 in c:\\users\\carme\\anaconda3\\lib\\site-packages (from pyarrow) (1.26.4)\n"
     ]
    }
   ],
   "source": [
    "pip install pyarrow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a620fca8-86f5-4646-9161-f872f6670e18",
   "metadata": {},
   "source": [
    "**Vamos a cargar los dataset que hemos buscado en internet de una fuente fiable, se llaman train.parquet y test.parquet, nos interesaria ver el número de filas de cada archivo y también que nombre tienen las columnas y las etiquetas con las que se cataloga como spam o ham los mensajes.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62d12f78-9317-44bb-967a-73a40ef2cd52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- df_train_new cargado ---\n",
      "Filas: 8175\n",
      "Primeras 10 filas:\n",
      "                                                text     label\n",
      "0  hey I am looking for Xray baggage datasets can...  not_spam\n",
      "1  \"Get rich quick! Make millions in just days wi...      spam\n",
      "2  URGENT MESSAGE: YOU WON'T BELIEVE WHAT WE HAVE...      spam\n",
      "3  [Google AI Blog: Contributing Data to Deepfake...  not_spam\n",
      "4  Trying to see if anyone already has timestamps...  not_spam\n",
      "5  Bridging the gap between artificial intelligen...  not_spam\n",
      "6  hi all any good leads on datasets for fuel pri...  not_spam\n",
      "7   \\n\\nHi everyone,\\n\\nFor my thesis I'm looking...  not_spam\n",
      "8  I'm looking for a large dataset of n-grams (pr...  not_spam\n",
      "9  Check out these amazing weight loss pills! The...      spam\n",
      "\n",
      "Columnas y tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8175 entries, 0 to 8174\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    8175 non-null   object\n",
      " 1   label   8175 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 127.9+ KB\n",
      "None\n",
      "\n",
      "Etiquetas únicas en df_train_new['label'] (si existe): ['not_spam' 'spam']\n",
      "Etiquetas únicas en df_train_new['class_label'] (si existe): Columna class_label no encontrada\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- df_test_new cargado ---\n",
      "Filas: 2725\n",
      "Primeras 10 filas:\n",
      "                                                text     label\n",
      "0   Deezer.com 10,406,168 Artist DB\\n\\nWe have sc...  not_spam\n",
      "1  🚨 ATTENTION ALL USERS! 🚨\\n\\n🆘 Are you looking ...      spam\n",
      "2  I'm working on a stats project to test some of...  not_spam\n",
      "3  [[Sorry, I cannot generate inappropriate or sp...      spam\n",
      "4  L@@k at these Unbelievable diet pills that can...      spam\n",
      "5  Looking for a big list of units of measurement...  not_spam\n",
      "6  YOLO peeps! Are you ready to level up your soc...      spam\n",
      "7  I want to do a Datascience project on failed r...  not_spam\n",
      "8  Get rich quick! Join our amazing money-making ...      spam\n",
      "9  Upd8 Your W3b Pr0fil3! Click h3re!\\n\\nHeyyyy e...      spam\n",
      "\n",
      "Columnas y tipos de datos:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2725 entries, 0 to 2724\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   text    2725 non-null   object\n",
      " 1   label   2725 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 42.7+ KB\n",
      "None\n",
      "\n",
      "Etiquetas únicas en df_test_new['label'] (si existe): ['not_spam' 'spam']\n",
      "Etiquetas únicas en df_test_new['class_label'] (si existe): Columna class_label no encontrada\n",
      "\n",
      "--- Carga y Exploración Inicial Completada ---\n",
      "Ahora tienes 'df_train_new' y 'df_test_new' en memoria para inspeccionar.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Cargar train.parquet ---\n",
    "try:\n",
    "    df_train_new = pd.read_parquet('train.parquet')\n",
    "    print(\"--- df_train_new cargado ---\")\n",
    "    print(f\"Filas: {len(df_train_new)}\")\n",
    "    print(\"Primeras 10 filas:\") # Modificado para mostrar 10 filas\n",
    "    print(df_train_new.head(10)) # Modificado para mostrar 10 filas\n",
    "    print(\"\\nColumnas y tipos de datos:\")\n",
    "    print(df_train_new.info())\n",
    "    print(f\"\\nEtiquetas únicas en df_train_new['label'] (si existe): {df_train_new['label'].unique() if 'label' in df_train_new.columns else 'Columna label no encontrada'}\")\n",
    "    print(f\"Etiquetas únicas en df_train_new['class_label'] (si existe): {df_train_new['class_label'].unique() if 'class_label' in df_train_new.columns else 'Columna class_label no encontrada'}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'train.parquet' no encontrado. Asegúrate de que el archivo está en la misma carpeta que este notebook.\")\n",
    "    df_train_new = pd.DataFrame() # Crear DataFrame vacío para evitar errores posteriores\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar 'train.parquet': {e}\")\n",
    "    df_train_new = pd.DataFrame()\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Separador visual\n",
    "\n",
    "# --- 2. Cargar test.parquet ---\n",
    "try:\n",
    "    df_test_new = pd.read_parquet('test.parquet')\n",
    "    print(\"--- df_test_new cargado ---\")\n",
    "    print(f\"Filas: {len(df_test_new)}\")\n",
    "    print(\"Primeras 10 filas:\") # Modificado para mostrar 10 filas\n",
    "    print(df_test_new.head(10)) # Modificado para mostrar 10 filas\n",
    "    print(\"\\nColumnas y tipos de datos:\")\n",
    "    print(df_test_new.info())\n",
    "    print(f\"\\nEtiquetas únicas en df_test_new['label'] (si existe): {df_test_new['label'].unique() if 'label' in df_test_new.columns else 'Columna label no encontrada'}\")\n",
    "    print(f\"Etiquetas únicas en df_test_new['class_label'] (si existe): {df_test_new['class_label'].unique() if 'class_label' in df_test_new.columns else 'Columna class_label no encontrada'}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: 'test.parquet' no encontrado. Asegúrate de que el archivo está en la misma carpeta que este notebook.\")\n",
    "    df_test_new = pd.DataFrame() # Crear DataFrame vacío\n",
    "except Exception as e:\n",
    "    print(f\"ERROR al cargar 'test.parquet': {e}\")\n",
    "    df_test_new = pd.DataFrame()\n",
    "\n",
    "print(\"\\n--- Carga y Exploración Inicial Completada ---\")\n",
    "print(\"Ahora tienes 'df_train_new' y 'df_test_new' en memoria para inspeccionar.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a9bf23a-61ae-483b-a659-360af1d989e2",
   "metadata": {},
   "source": [
    "**Veamos como lucían nuestras columnas en nuestro dataset inicial spam.csv, porque necesitamos que luzcan igual que los archivos parquet para poder fusionarlos correctamente.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "463b2092-a71e-409c-9ca7-3b0fea30783b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>spam</td>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2 Unnamed: 2  \\\n",
       "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
       "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
       "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
       "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
       "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
       "\n",
       "  Unnamed: 3 Unnamed: 4  \n",
       "0        NaN        NaN  \n",
       "1        NaN        NaN  \n",
       "2        NaN        NaN  \n",
       "3        NaN        NaN  \n",
       "4        NaN        NaN  \n",
       "5        NaN        NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original = pd.read_csv('spam.csv', sep=None, engine='python', encoding='latin-1')\n",
    "\n",
    "# ¡Aquí está tu tabla! Sin nada más.\n",
    "# Las columnas se llamarán según el contenido de la primera fila de tu CSV.\n",
    "df_original.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56b9dbb6-1eb3-4ce4-ba41-dfc26ab02e36",
   "metadata": {},
   "source": [
    "**Vamos a ver cuantas filas tenía nuestro spam.csv:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a659c692-18ac-4982-8615-2023fe9cdfc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_original)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc105ed0-1bfa-4292-8591-fcceeebb0726",
   "metadata": {},
   "source": [
    "**Vamos a eliminar las columnas irrelevantes de spam.csv y a renombrar y reordenar las columnas v1 y v2 para conseguir el formato de los archivos parquet.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e8be855-4ceb-41c9-a3d4-b3650fc6bd09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Advertencia: 'spam.csv' detectado con 5 columnas. Reduciendo a 2.\n",
      "Fila 'v1 v2' eliminada del DataFrame original.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>FreeMsg Hey there darling it's been 3 week's n...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Even my brother is not like to speak with me. ...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>As per your request 'Melle Melle (Oru Minnamin...</td>\n",
       "      <td>not_spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>WINNER!! As a valued network customer you have...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Had your mobile 11 months or more? U R entitle...</td>\n",
       "      <td>spam</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text     label\n",
       "1   Go until jurong point, crazy.. Available only ...  not_spam\n",
       "2                       Ok lar... Joking wif u oni...  not_spam\n",
       "3   Free entry in 2 a wkly comp to win FA Cup fina...      spam\n",
       "4   U dun say so early hor... U c already then say...  not_spam\n",
       "5   Nah I don't think he goes to usf, he lives aro...  not_spam\n",
       "6   FreeMsg Hey there darling it's been 3 week's n...      spam\n",
       "7   Even my brother is not like to speak with me. ...  not_spam\n",
       "8   As per your request 'Melle Melle (Oru Minnamin...  not_spam\n",
       "9   WINNER!! As a valued network customer you have...      spam\n",
       "10  Had your mobile 11 months or more? U R entitle...      spam"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_original_raw = pd.read_csv('spam.csv', sep=None, engine='python', header=None, encoding='latin-1')\n",
    "\n",
    "# --- Verificación y Reducción a 2 Columnas ---\n",
    "# Forzamos que el DataFrame solo tenga las dos primeras columnas.\n",
    "if df_original_raw.shape[1] > 2:\n",
    "    print(f\"Advertencia: 'spam.csv' detectado con {df_original_raw.shape[1]} columnas. Reduciendo a 2.\")\n",
    "    df_original_raw = df_original_raw.iloc[:, :2].copy() # Reasignamos el DataFrame a 2 columnas\n",
    "\n",
    "# Asignamos los nombres de las columnas.\n",
    "df_original_raw.columns = ['v1_label', 'v2_text']\n",
    "\n",
    "# --- ¡NUEVO PASO CRUCIAL AQUÍ! ---\n",
    "# Eliminamos la primera fila (índice 0) que contiene 'v1' y 'v2' como datos.\n",
    "df_original_raw = df_original_raw.iloc[1:].copy()\n",
    "print(\"Fila 'v1 v2' eliminada del DataFrame original.\")\n",
    "\n",
    "\n",
    "# --- CONTINUACIÓN DE LAS TRANSFORMACIONES SOLICITADAS ---\n",
    "\n",
    "# 1. Eliminar las columnas Unnamed (este paso ahora es redundante).\n",
    "# Seleccionamos solo las columnas que nos interesan: 'v1_label' y 'v2_text'.\n",
    "df_transformado = df_original_raw[['v1_label', 'v2_text']].copy()\n",
    "\n",
    "# 2. Reordenar y renombrar columnas\n",
    "# Queremos 'v2_text' como primera columna y que se llame 'text'.\n",
    "# Queremos 'v1_label' como segunda columna y que se llame 'label'.\n",
    "df_transformado = df_transformado.rename(columns={'v2_text': 'text', 'v1_label': 'label'})\n",
    "df_transformado = df_transformado[['text', 'label']] # Aseguramos el orden: 'text' primero, 'label' segundo\n",
    "\n",
    "# 3. Sustituir valores en la columna 'label'\n",
    "# Donde pone 'ham', debe poner 'not_spam'. 'spam' se queda igual.\n",
    "df_transformado['label'] = df_transformado['label'].replace({'ham': 'not_spam'})\n",
    "\n",
    "# 4. Mostrar las primeras 10 filas del DataFrame transformado en formato tabla\n",
    "df_transformado.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332cb24d-acc1-4701-8995-c31fa06c4499",
   "metadata": {},
   "source": [
    "**Comprobamos que no haya nulos en el nuevo dataframe**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6362f940-1f63-4665-baea-10b0627fee76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_transformado por columna:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Suponiendo que df_transformado ya está cargado en tu entorno\n",
    "# y tiene las columnas 'text' y 'label'.\n",
    "\n",
    "# Muestra la cantidad de valores nulos por cada columna del DataFrame\n",
    "print(\"Valores nulos en df_transformado por columna:\")\n",
    "print(df_transformado.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa9a342-24d0-4d3e-ba38-2c33fb395030",
   "metadata": {},
   "source": [
    "**Compribamos que se conserve el número de filas que tenia el original**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abc18b64-2d7b-4da1-9fb0-e549f8e10850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5572"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_transformado)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42033db9-c5d5-43d7-bdaf-82d823ab9d32",
   "metadata": {},
   "source": [
    "**Guardo el nuevo df transformado en un csv llamado nuevo_spam.csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7bf048e1-91ee-4a49-bff5-ee8f8da3da74",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_transformado.to_csv('nuevo_spam.csv', index=False, encoding='latin-1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736cd947-d530-4855-a697-85896fb9feb0",
   "metadata": {},
   "source": [
    "**Procedemos a combinar los 3 archivos para conseguir el resultado final, un dataset más rico en variedad de mensajes puesto que nuestro primer modelo cometía algunos errores clasificando spam ( de camino hemos eliminado filas duplicadas).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ac53a0a9-2696-4fc8-a8e5-47347ba25d3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 'nuevo_spam.csv' loaded ---\n",
      "Rows: 5572\n",
      "Columns: ['text', 'label'], Labels: ['not_spam' 'spam']\n",
      "Nulls in 'label' column of df_nuevo_spam: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- 'train.parquet' loaded ---\n",
      "Rows: 8175\n",
      "Columns: ['text', 'label'], Labels: ['not_spam' 'spam']\n",
      "Nulls in 'label' column of df_train_new: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- 'test.parquet' loaded ---\n",
      "Rows: 2725\n",
      "Columns: ['text', 'label'], Labels: ['not_spam' 'spam']\n",
      "Nulls in 'label' column of df_test_new: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- 'train.parquet' transformed (no mapping needed) ---\n",
      "Columns: ['text', 'label'], Labels: ['not_spam' 'spam']\n",
      "Nulls in 'label' column of df_train_transformed: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- 'test.parquet' transformed (no mapping needed) ---\n",
      "Columns: ['text', 'label'], Labels: ['not_spam' 'spam']\n",
      "Nulls in 'label' column of df_test_transformed: 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- All DataFrames concatenated (before dropping duplicates) ---\n",
      "Total rows: 16472\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- Final combined DataFrame (after dropping duplicates) ---\n",
      "Final rows: 15831\n",
      "Final labels: ['not_spam' 'spam']\n",
      "Nulls in 'label' column of df_final_combined (final check): 0\n",
      "\n",
      "================================================================================\n",
      "\n",
      "--- First 10 rows of the final combined DataFrame ---\n",
      "\n",
      "--- Final combined DataFrame saved as 'spam_dataset.csv' ---\n",
      "File 'spam_dataset.csv' created with 15831 rows.\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Load nuevo_spam.csv ---\n",
    "# Assuming nuevo_spam.csv is already correctly formatted with 'text' and 'label' columns\n",
    "# and 'spam'/'not_spam' labels.\n",
    "df_nuevo_spam = pd.read_csv('nuevo_spam.csv', encoding='latin-1')\n",
    "print(\"--- 'nuevo_spam.csv' loaded ---\")\n",
    "print(f\"Rows: {len(df_nuevo_spam)}\")\n",
    "print(f\"Columns: {df_nuevo_spam.columns.tolist()}, Labels: {df_nuevo_spam['label'].unique()}\")\n",
    "# Comprobación de nulos en nuevo_spam.csv (debería ser 0)\n",
    "print(f\"Nulls in 'label' column of df_nuevo_spam: {df_nuevo_spam['label'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# --- 2. Load train.parquet ---\n",
    "df_train_new = pd.read_parquet('train.parquet')\n",
    "print(\"--- 'train.parquet' loaded ---\")\n",
    "print(f\"Rows: {len(df_train_new)}\")\n",
    "print(f\"Columns: {df_train_new.columns.tolist()}, Labels: {df_train_new['label'].unique()}\")\n",
    "# Comprobación de nulos en train.parquet (debería ser 0)\n",
    "print(f\"Nulls in 'label' column of df_train_new: {df_train_new['label'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# --- 3. Load test.parquet ---\n",
    "df_test_new = pd.read_parquet('test.parquet')\n",
    "print(\"--- 'test.parquet' loaded ---\")\n",
    "print(f\"Rows: {len(df_test_new)}\")\n",
    "print(f\"Columns: {df_test_new.columns.tolist()}, Labels: {df_test_new['label'].unique()}\")\n",
    "# Comprobación de nulos en test.parquet (debería ser 0)\n",
    "print(f\"Nulls in 'label' column of df_test_new: {df_test_new['label'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# --- 4. Transform Parquet DataFrames to match nuevo_spam.csv format ---\n",
    "\n",
    "# Transform df_train_new\n",
    "df_train_transformed = df_train_new.copy()\n",
    "# ¡CORREGIDO! ELIMINAMOS LA LÍNEA DE MAPEO, YA NO ES NECESARIA\n",
    "# df_train_transformed['label'] = df_train_transformed['label'].map({0: 'not_spam', 1: 'spam'})\n",
    "df_train_transformed = df_train_transformed[['text', 'label']] # Aseguramos el orden de las columnas\n",
    "\n",
    "print(\"--- 'train.parquet' transformed (no mapping needed) ---\")\n",
    "print(f\"Columns: {df_train_transformed.columns.tolist()}, Labels: {df_train_transformed['label'].unique()}\")\n",
    "print(f\"Nulls in 'label' column of df_train_transformed: {df_train_transformed['label'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# Transform df_test_new\n",
    "df_test_transformed = df_test_new.copy()\n",
    "# ¡CORREGIDO! ELIMINAMOS LA LÍNEA DE MAPEO, YA NO ES NECESARIA\n",
    "# df_test_transformed['label'] = df_test_transformed['label'].map({0: 'not_spam', 1: 'spam'})\n",
    "df_test_transformed = df_test_transformed[['text', 'label']] # Aseguramos el orden de las columnas\n",
    "\n",
    "print(\"--- 'test.parquet' transformed (no mapping needed) ---\")\n",
    "print(f\"Columns: {df_test_transformed.columns.tolist()}, Labels: {df_test_transformed['label'].unique()}\")\n",
    "print(f\"Nulls in 'label' column of df_test_transformed: {df_test_transformed['label'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# --- 5. Concatenate all three transformed DataFrames into a single new DataFrame ---\n",
    "# We use ignore_index=True to reset the index of the combined DataFrame\n",
    "df_final_combined = pd.concat([df_nuevo_spam, df_train_transformed, df_test_transformed], ignore_index=True)\n",
    "print(f\"--- All DataFrames concatenated (before dropping duplicates) ---\")\n",
    "print(f\"Total rows: {len(df_final_combined)}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# --- 6. Remove duplicates from the final combined DataFrame ---\n",
    "# Drop rows where both 'text' and 'label' are identical\n",
    "df_final_combined.drop_duplicates(subset=['text', 'label'], inplace=True)\n",
    "print(f\"--- Final combined DataFrame (after dropping duplicates) ---\")\n",
    "print(f\"Final rows: {len(df_final_combined)}\")\n",
    "print(f\"Final labels: {df_final_combined['label'].unique()}\")\n",
    "# ¡CRUCIAL! Verificar nulos en el DataFrame final\n",
    "print(f\"Nulls in 'label' column of df_final_combined (final check): {df_final_combined['label'].isnull().sum()}\")\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\") # Visual separator\n",
    "\n",
    "# --- 7. Display the first 10 rows of the final combined DataFrame ---\n",
    "print(\"--- First 10 rows of the final combined DataFrame ---\")\n",
    "df_final_combined.head(10)\n",
    "\n",
    "# --- 8. Save the final combined DataFrame to a new CSV file ---\n",
    "df_final_combined.to_csv('spam_dataset.csv', index=False, encoding='utf-8')\n",
    "print(\"\\n--- Final combined DataFrame saved as 'spam_dataset.csv' ---\")\n",
    "print(f\"File 'spam_dataset.csv' created with {len(df_final_combined)} rows.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95bdc695-c6d2-4f23-91b9-a717482d5d91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_train_new por columna:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos en df_train_new por columna:\")\n",
    "print(df_train_new.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0da36077-fec7-4965-a109-f1d143657433",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_test_new por columna:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos en df_test_new por columna:\")\n",
    "print(df_test_new.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2b34b85a-a46a-4248-90e3-6bb11928a226",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_test_transformed por columna:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos en df_test_transformed por columna:\")\n",
    "print(df_test_transformed.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6d3a78d5-0e19-4060-b35b-b4e803b945a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_train_transformed por columna:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Valores nulos en df_train_transformed por columna:\")\n",
    "print(df_train_transformed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964fb007-8c64-4bcb-b061-08f0f2815ef8",
   "metadata": {},
   "source": [
    "**Comprobamos que la longitud de nuestro dataframe es correcta:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0f3d35ad-48d3-42cb-92d4-c69ea64dd2a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15831"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_final_combined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4931456c-3838-4a28-8ec4-6fb6c3a660e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores nulos en df_final_combined por columna:\n",
      "text     0\n",
      "label    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Muestra la cantidad de valores nulos por cada columna del DataFrame df_final_combined\n",
    "print(\"Valores nulos en df_final_combined por columna:\")\n",
    "print(df_final_combined.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adc364a4-ca9b-4086-ade2-fe5eb4166366",
   "metadata": {},
   "source": [
    "**Guardamos en un csv nuestro nuevo dataset:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8beb2f53-a484-40d7-b6cc-6f2198020a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame 'df_final_combined' guardado como 'spam_dataset.csv'.\n"
     ]
    }
   ],
   "source": [
    "# Este código lo guardará el nuevo df en un archivo CSV.\n",
    "df_final_combined.to_csv('spam_dataset.csv', index=False, encoding='utf-8')\n",
    "\n",
    "# Mensaje de confirmación (esto se imprimirá en la salida de la celda)\n",
    "print(\"DataFrame 'df_final_combined' guardado como 'spam_dataset.csv'.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efba1d78-1572-41a4-aa92-f45927d88162",
   "metadata": {},
   "source": [
    "**María del Carmen Martín Rodríguez, 16/07/2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb5c88-9248-4fb5-8b17-80ae8550787d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
