# üöÄ DATA SCIENCE PROJECT SPAM DETECTION üöÄ
¬°Bienvenido a la API de Detecci√≥n de Spam SMS! Este proyecto es el resultado de un esfuerzo por crear una soluci√≥n robusta y reproducible para clasificar mensajes de texto como "SPAM" o "HAM" (no spam) utilizando t√©cnicas de Machine Learning y despleg√°ndola como un servicio web con Docker.

## ‚ú® Esencia del Proyecto
El coraz√≥n de este proyecto es un modelo de Machine Learning entrenado para identificar patrones en mensajes SMS que indican si son spam o no. Hemos transformado este modelo en una API accesible a trav√©s de HTTP, lo que permite a cualquier aplicaci√≥n o servicio enviar un mensaje y recibir una predicci√≥n instant√°nea. Todo esto est√° empaquetado en un contenedor Docker, garantizando que la API funcione de manera consistente en cualquier entorno.

## üìä DATA COLLECTION
La calidad de los datos es fundamental. Para este proyecto, utilizamos y expandimos nuestro dataset:

**Dataset Inicial (spam.csv):** Comenzamos con un dataset cl√°sico de detecci√≥n de spam SMS, ampliamente utilizado en la comunidad de Machine Learning, a menudo disponible en repositorios como el UCI Machine Learning Repository. Este dataset nos proporcion√≥ una base s√≥lida de mensajes etiquetados.

**Nuevos Datos (train.parquet, test.parquet):** Tras una fase inicial de desarrollo, identificamos la necesidad de mejorar la robustez del modelo. Esto nos llev√≥ a una fase de expansi√≥n y mejora del dataset, donde los datos originales fueron procesados, posiblemente combinados con fuentes adicionales o enriquecidos, y luego divididos en formatos train.parquet y test.parquet para una gesti√≥n m√°s eficiente y un mejor rendimiento en el entrenamiento. Estos archivos representan la versi√≥n final y optimizada de nuestro conjunto de datos para el entrenamiento y evaluaci√≥n.

## üßπ DATA WRANLING (Procesamiento de Datos)
El texto es ruidoso, y para que nuestros modelos lo entiendan, necesitamos limpiarlo a fondo. Realizamos un proceso de preprocesamiento riguroso y consistente:

### **Fase Inicial (con spam.csv):**

- **Conversi√≥n a Min√∫sculas:** Estandarizaci√≥n de todo el texto.

- **Eliminaci√≥n de Caracteres No Alfab√©ticos:** Eliminaci√≥n de n√∫meros, s√≠mbolos y puntuaci√≥n, reemplaz√°ndolos con espacios para no unir palabras.

- **Tokenizaci√≥n:** Divisi√≥n de los mensajes en palabras individuales.

- **Eliminaci√≥n de Stopwords:** Eliminaci√≥n de palabras comunes (ej., "el", "la", "y") que no aportan significado a la clasificaci√≥n.

- **Stemming (Porter Stemmer):** Reducci√≥n de las palabras a su ra√≠z (ej., "corriendo" -> "corr", "mejoras" -> "mejor") para unificar t√©rminos relacionados.

- **Normalizaci√≥n de Espacios:** Eliminaci√≥n de m√∫ltiples espacios y espacios al inicio/final.

## **Fase de Mejora (con train.parquet, test.parquet):**

Se aplicaron exactamente los mismos pasos de preprocesamiento de manera consistente a los nuevos datos para asegurar la uniformidad y evitar sesgos en el modelo. La consistencia en el preprocesamiento es crucial para que el modelo interprete correctamente los datos nuevos.

##  FEATURE ENGINEERING ‚öôÔ∏è

Para transformar el texto limpio en un formato num√©rico que el modelo pueda procesar, utilizamos:

- **Vectorizaci√≥n TF-IDF (Term Frequency-Inverse Document Frequency):** Esta t√©cnica asigna un peso num√©rico a cada palabra, reflejando su importancia en un mensaje y en el conjunto total de mensajes. Nos permiti√≥ capturar la relevancia de los t√©rminos en la detecci√≥n de spam.

- **Longitud del Mensaje:** A√±adimos la longitud del mensaje preprocesado como una caracter√≠stica num√©rica adicional. Esta caracter√≠stica result√≥ ser muy potente, ya que los mensajes de spam suelen tener longitudes muy diferentes a los mensajes leg√≠timos.

## üß† DESARROLLO Y EVALUACI√ìN DE LOS MODELOS

A lo largo del proyecto, exploramos diferentes algoritmos de Machine Learning:

- **Modelos Iniciales:** Comenzamos con modelos como Naive Bayes, que son un buen punto de partida para la clasificaci√≥n de texto.

- **Iteraci√≥n y Mejora:** Tras evaluar el rendimiento inicial, identificamos √°reas de mejora. Esto nos llev√≥ a la decisi√≥n de incorporar m√°s datos y refinar nuestro enfoque.

- **Modelo Campe√≥n (Regresi√≥n Log√≠stica Afinada):** Finalmente, optamos por un modelo de Regresi√≥n Log√≠stica. Este modelo fue afinado (optimizando sus hiperpar√°metros) para lograr la m√°xima precisi√≥n y robustez en la clasificaci√≥n de spam. La combinaci√≥n de la vectorizaci√≥n TF-IDF y la caracter√≠stica de longitud del mensaje con este modelo result√≥ ser la m√°s efectiva.

## üåê Construcci√≥n y Dockerizaci√≥n de la API

El objetivo final era hacer que nuestro modelo fuera accesible.

- **Primera Iteraci√≥n de la API:** Construimos una API inicial con Flask para exponer el modelo. Sin embargo, al probarla, nos dimos cuenta de que el modelo inicial y el dataset no eran lo suficientemente robustos.

- **Mejora Continua:** Esto nos impuls√≥ a una segunda fase de desarrollo, donde obtuvimos y procesamos m√°s datos, y entrenamos el modelo de Regresi√≥n Log√≠stica afinado.

- **Dockerizaci√≥n (¬°El Desaf√≠o Final!):** Para garantizar la reproducibilidad y facilitar el despliegue, decidimos contenerizar la API con Docker. Este proceso implic√≥:

- Definir el entorno Python y las dependencias en Dockerfile y requirements.txt.

- Asegurar que los datos de NLTK (como las stopwords) se descargaran correctamente dentro del contenedor, lo cual fue un desaf√≠o debido a la naturaleza aislada de Docker.

- Manejar las versiones de Python y librer√≠as para evitar conflictos.

¬°Finalmente, lo logramos! La API ahora se empaqueta y ejecuta perfectamente en un contenedor Docker, lista para ser utilizada en cualquier entorno.

## üöÄ C√≥mo Usar y Probar la API 

¬°Si quieres ver esta API en acci√≥n, sigue estos sencillos pasos!

**1. Requisitos Previos**
  
Necesitar√°s tener Docker Desktop (para Windows/macOS) o Docker Engine (para Linux) instalado en tu sistema. Puedes descargarlo desde docker.com.

_Nota: Tambi√©n puedes optar por ejecutar Docker dentro de una m√°quina virtual (VM) con un sistema operativo Linux (como Ubuntu), tal como se hizo en el desarrollo de este proyecto. Esto proporciona un entorno aislado y controlado para Docker._  

**2. Clonar el Repositorio**
  
Abre tu terminal (o Git Bash/PowerShell en Windows) y clona este repositorio:

```
git clone https://github.com/Mai-de-jerez/Data_Science_project_Spam_Detection.git
cd Data_Science_project_Spam_Detectio
```

**3. Construir la Imagen Docker**
  
Una vez dentro de la carpeta del proyecto, construye la imagen Docker. Este comando descargar√° la imagen base de Python, instalar√° todas las dependencias (incluyendo scikit-learn, nltk, numpy, scipy, flask, joblib) y descargar√° los datos de NLTK necesarios.

```
docker build -t spam-detector-api .
```

Este proceso puede tardar unos minutos la primera vez, ya que Docker necesita descargar las capas necesarias.

**4. Lanzar el Contenedor Docker**
  
Una vez que la imagen se haya construido con √©xito, lanza el contenedor. Esto iniciar√° tu API de Flask en el puerto 5000 de tu m√°quina.

```
docker run -p 5000:5000 spam-detector-api
```

Ver√°s los mensajes de inicio de Flask en tu terminal. Deja esta terminal abierta, ya que es donde se est√° ejecutando la API.

**5. Probar la API**
  
Ahora, abre una segunda terminal (o usa una herramienta como Postman o Insomnia) para enviar solicitudes a tu API.

La API espera solicitudes POST a la ruta /classify_sms con un cuerpo JSON que contenga la clave "message".

**Ejemplo de Mensaje SPAM (usando curl):**

```
curl -X POST -H "Content-Type: application/json" -d '{ "message": "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C'\''s apply." }' http://localhost:5000/classify_sms
```

Respuesta esperada:

```
{
  "original_message": "Free entry in 2 a wkly comp to win FA Cup final tkts 21st May 2005. Text FA to 87121 to receive entry question(std txt rate)T&C's apply.",
  "prediction": "SPAM",
  "preprocessed_message": "free entri wkli comp win fa cup final tkt st may text fa receiv entri question std txt rate c appli"
}
```

Ejemplo de Mensaje HAM (No Spam) (usando curl):

```
curl -X POST -H "Content-Type: application/json" -d '{ "message": "Hey, how are you doing today? Let'\''s catch up soon." }' http://localhost:5000/classify_sms
```

Respuesta esperada:

```
{
  "original_message": "Hey, how are you doing today? Let's catch up soon.",
  "prediction": "HAM",
  "preprocessed_message": "hey do today let catch soon"
}
```

¬°Y eso es todo! ¬°Ya tienes tu API de detecci√≥n de spam funcionando localmente!
